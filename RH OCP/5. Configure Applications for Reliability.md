## Application High Availability with Kubernetes

### Objectives

- Describe how Kubernetes tries to keep applications running after failures.
    

### Concepts of Deploying Highly Available Applications

_High availability_ (HA) is a goal of making applications more robust and resistant to runtime failures. Implementing HA techniques decreases the likelihood that an application is completely unavailable to users.

In general, HA can protect an application from failures in the following contexts:

- From itself in the form of application bugs
    
- From its environment, such as networking issues
    
- From other applications that exhaust cluster resources
    

Additionally, HA practices can protect the cluster from applications, such as one with a memory leak.

### Writing Reliable Applications

At its core, cluster-level HA tooling mitigates worst-case scenarios. HA is not a substitute for fixing application-level issues, but augments developer mitigations. Although required for reliability, application security is a separate concern.

Applications must work with the cluster so that Kubernetes can best handle failure scenarios. Kubernetes expects the following behaviors from applications:

- Tolerates restarts
    
- Responds to health probes, such as the startup, readiness, and liveness probes
    
- Supports multiple simultaneous instances
    
- Has well-defined and well-behaved resource usage
    
- Operates with restricted privileges
    

Although the cluster can run applications that lack the preceding behaviors, applications with these behaviors better use the reliability and HA features that Kubernetes provides.

Most HTTP-based applications provide an endpoint to verify application health. The cluster can be configured to observe this endpoint and mitigate potential issues for the application.

The application is responsible for providing such an endpoint. Developers must decide how the application determines its state.

For example, if an application depends on a database connection, then the application might respond with a healthy status only when the database is reachable. However, not all applications that make database connections need such a check. This decision is at the discretion of the developers.

### Kubernetes Application Reliability

If an application pod crashes, then it cannot respond to requests. Depending on the configuration, the cluster can automatically restart the pod. If the application fails without crashing the pod, then the pod does not receive requests. However, the cluster can do so only with the appropriate health probes.

Kubernetes uses the following HA techniques to improve application reliability:

- Restarting pods: By configuring a restart policy on a pod, the cluster restarts misbehaving instances of an application.
    
- Probing: By using health probes, the cluster knows when applications cannot respond to requests, and can automatically act to mitigate the issue.
    
- Horizontal scaling: When the application load changes, the cluster can scale the number of replicas to match the load.
    

These techniques are explored throughout this chapter.


## Application Health Probes

### Objectives

- Describe how Kubernetes uses health probes during deployment, scaling, and failover of applications.
    

### Kubernetes Probes

Health probes are an important part of maintaining a robust cluster. _Probes_ enable the cluster to determine the status of an application by repeatedly probing it for a response.

A set of health probes affect a cluster's ability to do the following tasks:

- Crash mitigation by automatically attempting to restart failing pods
    
- Failover and load balancing by sending requests only to healthy pods
    
- Monitoring by determining whether and when pods are failing
    
- Scaling by determining when a new replica is ready to receive requests
    

### Authoring Probe Endpoints

Application developers are expected to code health probe endpoints during application development. These endpoints determine the health and status of the application. For example, a data-driven application might report a successful health probe only if it can connect to the database.

Because the cluster calls them often, health probe endpoints should be quick to perform. Endpoints should not perform complicated database queries or many network calls.

### Probe Types

Kubernetes provides the following types of probes: startup, readiness, and liveness. Depending on the application, you might configure one or more of these types.

#### Readiness Probes

A _readiness probe_ determines whether the application is ready to serve requests. If the readiness probe fails, then Kubernetes prevents client traffic from reaching the application by removing the pod's IP address from the service resource.

Readiness probes help to detect temporary issues that might affect your applications. For example, the application might be temporarily unavailable when it starts, because it must establish initial network connections, load files in a cache, or perform initial tasks that take time to complete. The application might occasionally need to run long batch jobs, which make it temporarily unavailable to clients.

Kubernetes continues to run the probe even after the application fails. If the probe succeeds again, then Kubernetes adds back the pod's IP address to the service resource, and requests are sent to the pod again.

In such cases, the readiness probe addresses a temporary issue and improves application availability.

#### Liveness Probes

Like a readiness probe, a _liveness probe_ is called throughout the lifetime of the application. Liveness probes determine whether the application container is in a healthy state. If an application fails its liveness probe enough times, then the cluster restarts the pod according to its restart policy.

Unlike a startup probe, liveness probes are called after the application's initial start process. Usually, this mitigation is by restarting or re-creating the pod.

#### Startup Probes

A _startup probe_ determines when an application's startup is completed. Unlike a liveness probe, a startup probe is not called after the probe succeeds. If the startup probe does not succeed after a configurable timeout, then the pod is restarted based on its `restartPolicy` value.

Consider adding a startup probe to applications with a long start time. By using a startup probe, the liveness probe can remain short and responsive.

### Types of Tests

When defining a probe, you must specify one of the following types of test to perform:

HTTP GET

Each time that the probe runs, the cluster sends a request to the specified HTTP endpoint. The test is considered a success if the request responds with an HTTP response code between `200` and `399`. Other responses cause the test to fail.

Container command

Each time that the probe runs, the cluster runs the specified command in the container. If the command exits with a status code of `0`, then the test succeeds. Other status codes cause the test to fail.

TCP socket

Each time that the probe runs, the cluster attempts to open a socket to the container. The test succeeds only if the connection is established.

### Timings and Thresholds

All the types of probes include timing variables. The _period seconds_ variable defines how often the probe runs. The _failure threshold_ defines how many failed attempts are required before the probe itself fails.

For example, a probe with a failure threshold of `3` and period seconds of `5` can fail up to three times before the overall probe fails. Using this probe configuration means that the issue can exist for 10 seconds before it is mitigated. However, running probes too often can waste resources. Consider these values when setting probes.

### Adding Probes via YAML

Because probes are defined on a pod template, probes can be added to workload resources such as deployments. To add a probe to an existing deployment, update and apply the YAML file or use the `oc edit` command. For example, the following YAML excerpt defines a deployment pod template with a probe:

apiVersion: apps/v1
kind: Deployment
_...output omitted..._
spec:
_...output omitted..._
  template:
    spec:
      containers:
      - name: web-server
        _...output omitted..._
        livenessProbe: ![1](https://rol.redhat.com/rol/static/roc/Common_Content/images/1.svg)
          failureThreshold: 6 ![2](https://rol.redhat.com/rol/static/roc/Common_Content/images/2.svg)
          periodSeconds: 10 ![3](https://rol.redhat.com/rol/static/roc/Common_Content/images/3.svg)
          httpGet: ![4](https://rol.redhat.com/rol/static/roc/Common_Content/images/4.svg)
            path: /health ![5](https://rol.redhat.com/rol/static/roc/Common_Content/images/5.svg)
            port: 3000 ![6](https://rol.redhat.com/rol/static/roc/Common_Content/images/6.svg)

|   |   |
|---|---|
|[![1](https://rol.redhat.com/rol/static/roc/Common_Content/images/1.svg)](https://rol.redhat.com/rol/app/#_adding_probes_via_yaml-CO32-1)|Defines a liveness probe.|
|[![2](https://rol.redhat.com/rol/static/roc/Common_Content/images/2.svg)](https://rol.redhat.com/rol/app/#_adding_probes_via_yaml-CO32-2)|Specifies how many times the probe must fail before mitigating.|
|[![3](https://rol.redhat.com/rol/static/roc/Common_Content/images/3.svg)](https://rol.redhat.com/rol/app/#_adding_probes_via_yaml-CO32-3)|Defines how often the probe runs.|
|[![4](https://rol.redhat.com/rol/static/roc/Common_Content/images/4.svg)](https://rol.redhat.com/rol/app/#_adding_probes_via_yaml-CO32-4)|Sets the probe as an HTTP request and defines the request port and path.|
|[![5](https://rol.redhat.com/rol/static/roc/Common_Content/images/5.svg)](https://rol.redhat.com/rol/app/#_adding_probes_via_yaml-CO32-5)|Specifies the HTTP path to send the request to.|
|[![6](https://rol.redhat.com/rol/static/roc/Common_Content/images/6.svg)](https://rol.redhat.com/rol/app/#_adding_probes_via_yaml-CO32-6)|Specifies the port to send the HTTP request over.|

### Adding Probes via the CLI

The `oc set probe` command adds or modifies a probe on a deployment. For example, the following command adds a readiness probe to a deployment called `front-end`:

[user@host ~]$ **`oc set probe deployment/front-end \ --readiness \ ![1](https://rol.redhat.com/rol/static/roc/Common_Content/images/1.svg) --failure-threshold 6 \ ![2](https://rol.redhat.com/rol/static/roc/Common_Content/images/2.svg) --period-seconds 10 \ ![3](https://rol.redhat.com/rol/static/roc/Common_Content/images/3.svg) --get-url http://:8080/healthz`** ![4](https://rol.redhat.com/rol/static/roc/Common_Content/images/4.svg)

|   |   |
|---|---|
|[![1](https://rol.redhat.com/rol/static/roc/Common_Content/images/1.svg)](https://rol.redhat.com/rol/app/#_adding_probes_via_the_cli-CO33-1)|Defines a readiness probe.|
|[![2](https://rol.redhat.com/rol/static/roc/Common_Content/images/2.svg)](https://rol.redhat.com/rol/app/#_adding_probes_via_the_cli-CO33-2)|Sets how many times the probe must fail before mitigating.|
|[![3](https://rol.redhat.com/rol/static/roc/Common_Content/images/3.svg)](https://rol.redhat.com/rol/app/#_adding_probes_via_the_cli-CO33-3)|Sets how often the probe runs.|
|[![4](https://rol.redhat.com/rol/static/roc/Common_Content/images/4.svg)](https://rol.redhat.com/rol/app/#_adding_probes_via_the_cli-CO33-4)|Sets the probe as an HTTP request, and defines the request port and path.|

### Adding Probes via the Web Console

To add or modify a probe on a deployment from the web console, navigate to the Workloads → Deployments menu and select a deployment.

|   |
|---|
|![](https://static.ole.redhat.com/rhls/courses/do180-4.14/images/reliability/probes/assets/deployments.png)|

Click Actions and then click Add Health Checks.

|   |
|---|
|![](https://static.ole.redhat.com/rhls/courses/do180-4.14/images/reliability/probes/assets/addprobes.png)|

Click Edit probe to specify the readiness type, the HTTP headers, the path, the port, and more.

|   |
|---|
|![](https://static.ole.redhat.com/rhls/courses/do180-4.14/images/reliability/probes/assets/editprobes.png)|

---
**Note

The `set probe` command is exclusive to RHOCP and `oc`.

---


## Reserve Compute Capacity for Applications

### Objectives

- Configure an application with resource requests so Kubernetes can make scheduling decisions.
    

### Kubernetes Pod Scheduling

The Red Hat OpenShift Container Platform (RHOCP) pod scheduler determines the placement of new pods onto nodes in the cluster. The pod scheduler algorithm follows a three-step process:

Filtering nodes

A pod can define a node selector that matches the labels in the cluster nodes. Only labels that match are eligible.

Additionally, the scheduler filters the list of running nodes by evaluating each node against a set of predicates. A pod can define _resource requests_ for compute resources such as CPU, memory, and storage. Only nodes with enough available computer resources are eligible.

The filtering step reduces the list of eligible nodes. In some cases, the pod could run on any of the nodes. In other cases, all the nodes are filtered out, so the pod cannot be scheduled until a node with the appropriate prerequisites becomes available.

If all nodes are filtered out, then a `FailedScheduling` event is generated for the pod.

Prioritizing the filtered list of nodes

By using multiple priority criteria, the scheduler determines a weighted score for each node. Nodes with higher scores are better candidates to run the pod.

Selecting the best fit node

The candidate list is sorted according to these scores, and the node with the highest score is selected to host the pod. If multiple nodes have the same high score, then one node is selected in a round-robin fashion. After a host is selected, then a `Scheduled` event is generated for the pod.

The scheduler is flexible and can be customized for advanced scheduling situations. Customizing the scheduler is outside the scope of this course.

### Compute Resource Requests

For such applications that require a specific amount of compute resources, you can define a resource request in the pod definition of your application deployment. The resource requests assign hardware resources for the application deployment.

Resource requests specify the minimum required compute resources necessary to schedule a pod. The scheduler tries to find a node with enough compute resources to satisfy the pod requests.

In Kubernetes, memory resources are measured in bytes, and CPU resources are measured in CPU units. CPU units are allocated by using millicore units. A millicore is a CPU core, either virtual or physical, that is split into 1000 units. A request value of `"1000 m"` allocates an entire CPU core to a pod. You can also use fractional values to allocate CPU resources. For example, you can set the CPU resource request to a `0.1` value, which represents 100 millicores (`100 m`). Likewise, a CPU resource request with a `1.0` value represents an entire CPU or 1000 millicores (`1000 m`).

You can define resource requests for each container in either a deployment or a deployment configuration resource. If resources are not defined, then the container specification shows a `resources: {}` line.

In your deployment, modify the `resources: {}` line to specify the chosen requests. The following example defines a resource request of 100 millicores (`100 m`) of CPU and one gibibyte (`1 Gi`) of memory.

```yaml
_...output omitted..._
    spec:
      containers:
      - image: quay.io/redhattraining/hello-world-nginx:v1.0
        name: hello-world-nginx
        resources:
          requests:
            cpu: "100m"
            memory: "1Gi"
```

If you use the `edit` command to modify a deployment or a deployment configuration, then ensure that you use the correct indentation. Indentation mistakes can result in the editor refusing to save changes. Alternatively, use the `set resources` command that the `kubectl` and `oc` commands provide, to specify resource requests. The following command sets the same requests as the preceding example:

```sh
[user@host ~]$ oc set resources deployment hello-world-nginx \ --requests cpu=10m,memory=1gi
```

The `set resource` command works with any resource that includes a pod template, such as the deployments and job resources.

### Inspecting Cluster Compute Resources

Cluster administrators can view the available and used compute resources of a node. For example, as a cluster administrator, you can use the `describe node` command to determine the compute resource capacity of a node. The command shows the capacity of the node and how much of that capacity is allocatable. It also displays the amount of allocated and requested resources on the node.
```sh
[user@host ~]$ oc describe node master01
Name:               master01
Roles:              control-plane,master,worker
_...output omitted..._
Capacity:
  cpu:                  8
  ephemeral-storage:    125293548Ki
  hugepages-1Gi:        0
  hugepages-2Mi:        0
  memory:               20531668Ki
  pods:                 250
Allocatable:
  cpu:                  7500m
  ephemeral-storage:    114396791822
  hugepages-1Gi:        0
  hugepages-2Mi:        0
  memory:               19389692Ki
  pods:                 250
_...output omitted..._
Non-terminated Pods:                                (88 in total)
  ... Name           CPU Requests  CPU Limits  Memory Requests  Memory Limits ...
  ... ----           ------------  ----------  ---------------  -------------
  ... controller-... 10m (0%)      0 (0%)      20Mi (0%)        0 (0%)        ...
  ... metallb-...    50m (0%)      0 (0%)      20Mi (0%)        0 (0%)        ...
  ... metallb-...    0 (0%)        0 (0%)      0 (0%)           0 (0%)        ...
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           `Requests`       Limits
  --------           `--------`       ------
  cpu                `3183m (42%)`    1202m (16%)
  memory             `12717Mi (67%)`  1350Mi (7%)
...output omitted...
```

RHOCP cluster administrators can also use the `oc adm top pods` command. This command shows the compute resource usage for each pod in a project. You must include the `--namespace` or `-n` options to specify a project. Otherwise, the command returns the resource usage for pods in the currently selected project.

The following command displays the resource usage for pods in the `openshift-dns` project:

```sh
[user@host ~]$ oc adm top pods -n openshift-dns
NAME                  CPU(cores)   MEMORY(bytes)
dns-default-5kpn5     1m           33Mi
node-resolver-6kdxp   0m           2Mi
```

Additionally, cluster administrators can use the `oc adm top node` command to view the resource usage of a cluster node. Include the node name to view the resource usage of a particular node.
```sh
[user@host ~]$ **`oc adm top node master01`**
NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
master01   1250m        16%    10268Mi         54%
```

## Limit Compute Capacity for Applications

### Objectives

- Configure an application with resource limits so Kubernetes can protect other applications from it.

Memory and CPU requests that you define for containers help Red Hat OpenShift Container Platform (RHOCP) to select a compute node to run your pods. However, these resource requests do not restrict the memory and CPU that the containers can use. For example, setting a memory request at 1 GiB does not prevent the container from consuming more memory.

Red Hat recommends that you set the memory and CPU requests to the peak usage of your application. In contrast, by setting lower values, you overcommit the node resources. If all the applications that are running on the node start to use resources above the values that they request, then the compute nodes might run out of memory and CPU.

In addition to requests, you can set memory and CPU _limits_ to prevent your applications from consuming too many resources.

### Setting Memory Limits

A memory limit specifies the amount of memory that a container can use across all its processes.

As soon as the container reaches the limit, the compute node selects and then kills a process in the container. When that event occurs, RHOCP detects that the application is not working any more, because the main container process is missing, or because the health probes report an error. RHOCP then restarts the container according to the pod `restartPolicy` attribute, which defaults to `Always`.

RHOCP relies on Linux kernel features to implement resource limits, and to kill processes in containers that reach their memory limits:

Control groups (cgroups)

RHOCP uses control groups to implement resource limits. Control groups are a Linux kernel mechanism for controlling and monitoring system resources, such as CPU and memory.

Out-of-Memory killer (OOM killer)

When a container reaches its memory limit, the Linux kernel triggers the OOM killer subsystem to select and then kill a process.

You must set a memory limit when the application has a memory usage pattern that you must mitigate, such as when the application has a memory leak. A memory leak is a bug in the application, which occurs when the application uses some memory but does not free it after use. If the leak appears in an infinite service loop, then the application uses more and more memory over time, and can end up consuming all the available memory on the system. For these applications, setting a memory limit prevents them from consuming all the node's memory. The memory limit also enables OpenShift to regularly restart applications to free up their memory when they reach the limit.

To set a memory limit for the container in a pod, use the `oc set resources` command:

[user@host ~]$ **`oc set resources deployment/hello --limits memory=1Gi`**

In addition to the `oc set resources` command, you can define resource limits from a file in the YAML format:

```yaml
apiVersion: apps/v1
kind: Deployment
_...output omitted..._
  spec:
    containers:
    - image: registry.access.redhat.com/ubi9/nginx-120:1-86
      name: hello
      resources:
        requests:
          cpu: 100m
          memory: 500Mi
        `limits:`
          cpu: 200m
          `memory: 1Gi`
```

When RHOCP restarts a pod because of an OOM event, it updates the pod's `lastState` attribute, and sets the reason to `OOMKilled`:

```
[user@host ~]$ oc get pod hello-67645f4865-vvr42 -o yaml
_...output omitted..._
status:
_...output omitted..._
  containerStatuses:
  - containerID: cri-o://806b...9fe7
    image: registry.access.redhat.com/ubi9/nginx-120:1-86
    imageID: registry.access.redhat.com/ubi9/nginx-120:1-86@sha256:1403...fd34
    `lastState:`
      terminated:
        containerID: cri-o://bbc4...9eb2
        exitCode: 137
        finishedAt: "2023-03-08T07:56:06Z"
        `reason: OOMKilled`
        startedAt: "2023-03-08T07:51:43Z"
    name: hello
    ready: true
    restartCount: 1
_...output omitted..._
```

To set a memory limit for the container in a pod from the web console, select a deployment, and click Actions → Edit resource limits.

|   |
|---|
|![](https://static.ole.redhat.com/rhls/courses/do180-4.14/images/reliability/limits/assets/selectresource.png)|

Set memory limits by increasing or decreasing the memory on the Limit section.

|   |
|---|
|![](https://static.ole.redhat.com/rhls/courses/do180-4.14/images/reliability/limits/assets/memory-limits.png)|

### Setting CPU Limits

CPU limits work differently from memory limits. When the container reaches the CPU limit, RHOCP inhibits the container's processes, even if the node has available CPU cycles. The application continues to work, but at a slower pace.

In contrast, if you do not set a CPU limit, then the container can consume as much CPU as is available on the node. If the node's CPU is under pressure, for example because several containers are running CPU-intensive tasks, then the Linux kernel shares the CPU resource between all these containers, according to the CPU requests value for the containers.

You must set a CPU limit when you require a consistent application behavior across clusters and nodes. For example, if the application runs on a node where the CPU is available, then the application can execute at full speed. On the other hand, if the application runs on a node with CPU pressure, then the application executes at a slower pace.

The same behavior can occur between your development and production clusters. Because the two environments might have different node configurations, the application might run differently when you move it from development to production.

### Note

Clusters can have differences in hardware configuration beyond what limits observe. For example, two clusters' nodes might have CPUs with equal core count and unequal clock speeds.

Requests and limits do not account for these hardware differences. If your clusters differ in such a way, take care that requests and limits are appropriate for both configurations.

By setting a CPU limit, you mitigate the differences between the configuration of the nodes, and you experience a more consistent behavior.

To set a CPU limit for the container in a pod, use the `oc set resources` command:

```sh
[user@host ~]$ oc set resources deployment/hello --limits cpu=200m
```

You can also define CPU limits from a file in the YAML format:

```yaml
apiVersion: apps/v1
kind: Deployment
_...output omitted..._
  spec:
    containers:
    - image: registry.access.redhat.com/ubi9/nginx-120:1-86
      name: hello
      resources:
        requests:
          cpu: 100m
          memory: 500Mi
        `limits:`
          `cpu: 200m`
          memory: 1Gi
```

To set a CPU limit for the container in a pod from the web console, select a deployment, and click Actions → Edit resource limits.

|   |
|---|
|![](https://static.ole.redhat.com/rhls/courses/do180-4.14/images/reliability/limits/assets/selectresource.png)|

Set CPU limits by increasing or decreasing the CPU on the Limit section.

|   |
|---|
|![](https://static.ole.redhat.com/rhls/courses/do180-4.14/images/reliability/limits/assets/cpu-limits.png)|

### Viewing Requests, Limits, and Actual Usage

By using the RHOCP command-line interface, cluster administrators can view compute usage information on individual nodes. The `oc describe node` command displays detailed information about a node, including information about the pods that are running on the node. For each pod, it shows CPU requests and limits, as well as memory requests and limits. If you do not specify a request or limit, then the pod shows a zero for that column. The command also displays a summary of all the resource requests and limits.

```sh
[user@host ~]$ oc describe node master01
Name:               master01
Roles:              control-plane,master,worker
_...output omitted..._
Non-terminated Pods:                                (88 in total)
  ... Name           CPU Requests  CPU Limits  Memory Requests  Memory Limits ...
  ... ----           ------------  ----------  ---------------  -------------
  ... controller-... 10m (0%)      0 (0%)      20Mi (0%)        0 (0%)        ...
  ... metallb-...    50m (0%)      0 (0%)      20Mi (0%)        0 (0%)        ...
  ... metallb-...    0 (0%)        0 (0%)      0 (0%)           0 (0%)        ...
_...output omitted..._
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests       `Limits`
  --------           --------       `------`
  cpu                3183m (42%)    `1202m (16%)`
  memory             12717Mi (67%)  `1350Mi (7%)`
_...output omitted..._
```

The `oc describe node` command displays requests and limits. The `oc adm top` command shows resource usage. The `oc adm top nodes` command shows the resource usage for nodes in the cluster. You must run this command as the cluster administrator.

The `oc adm top pods` command shows the resource usage for each pod in a project.

The following command displays the resource usage for the pods in the current project:

```sh
[user@host ~]$ oc adm top pods -n openshift-console
NAME                         CPU(cores)   MEMORY(bytes)
hello-67645f4865-vvr42       121m         309Mi
intradb-6f8d7cfffb-fz55b     0m           440Mi
```

To visualize the consumption of resources from the web console, select a deployment, and click the Metrics tab. From this tab, you can view the usage for memory, CPU, the file system, and incoming and outgoing traffic.

|   |
|---|
|![](https://static.ole.redhat.com/rhls/courses/do180-4.14/images/reliability/limits/assets/metrics-usage.png)|


## Application Autoscaling

### Objectives

- Configure a horizontal pod autoscaler for an application.

Kubernetes can autoscale a deployment based on current load on the application pods, by means of a `HorizontalPodAutoscaler` (HPA) resource type.

A horizontal pod autoscaler resource uses performance metrics that the OpenShift Metrics subsystem collects. The Metrics subsystem comes preinstalled in OpenShift. To autoscale a deployment, you must specify resource requests for pods so that the horizontal pod autoscaler can calculate the percentage of usage.

The autoscaler works in a loop. Every 15 seconds by default, it performs the following steps:

- The autoscaler retrieves the details of the metric for scaling from the HPA resource.
- For each pod that the HPA resource targets, the autoscaler collects the metric from the metric subsystem.
- For each targeted pod, the autoscaler computes the usage percentage, from the collected metric and from the pod resource requests.
- The autoscaler computes the average usage and the average resource requests across all the targeted pods. It establishes a usage ratio from these values, and then uses the ratio for its scaling decision.
    

The simplest way to create a horizontal pod autoscaler resource is by using the `oc autoscale` command, for example:

```sh
[user@host ~]$ oc autoscale deployment/hello --min 1 --max 10 --cpu-percent 80
```

The previous command creates a horizontal pod autoscaler resource that changes the number of replicas on the `hello` deployment to keep its pods under 80% of their total requested CPU usage.

The `oc autoscale` command creates a horizontal pod autoscaler resource by using the name of the deployment as an argument (`hello` in the previous example).

The maximum and minimum values for the horizontal pod autoscaler resource accommodate bursts of load and avoid overloading the OpenShift cluster. If the load on the application changes too quickly, then it might help to keep several spare pods to cope with sudden bursts of user requests. Conversely, too many pods can use up all cluster capacity and impact other applications that use the same OpenShift cluster.

To get information about horizontal pod autoscaler resources in the current project, use the `oc get` command. For example:

```sh
[user@host ~]$ oc get hpa
NAME   REFERENCE               TARGETS        MINPODS  MAXPODS  REPLICAS  ...
hello  Deployment/hello  <unknown>/80%        1        10       1         ...
scale  Deployment/scale        60%/80%        2        10       2         ...
```

---
**Important**

The horizontal pod autoscaler initially has a value of `<unknown>` in the `TARGETS` column. It might take up to five minutes before `<unknown>` changes to display a percentage for current usage.

A persistent value of `<unknown>` in the `TARGETS` column might indicate that the deployment does not define resource requests for the metric. The horizontal pod autoscaler does not scale these pods.

Pods that are created by using the `oc create deployment` command do not define resource requests. Using the OpenShift autoscaler might therefore require editing the deployment resources, creating custom YAML or JSON resource files for your application, or adding limit range resources to your project that define default resource requests.

---

In addition to the `oc autoscale` command, you can create a horizontal pod autoscaler resource from a file in the YAML format.

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: hello
spec:
  minReplicas: 1   # 1
  maxReplicas: 10  # 2
  metrics:
  - resource:
      name: cpu
      target:
        averageUtilization: 80  # 3
        type: Utilization
    type: Resource
  scaleTargetRef:  # 4
    apiVersion: apps/v1
    kind: Deployment
    name: hello
```

|     |                                                                                                                                                                                                                                                      |
| --- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1   | Minimum number of pods.                                                                                                                                                                                                                              |
| 2   | Maximum number of pods.                                                                                                                                                                                                                              |
| 3   | Ideal average CPU usage for each pod. If the global average CPU usage is above that value, then the horizontal pod autoscaler starts new pods. If the global average CPU usage is below that value, then the horizontal pod autoscaler deletes pods. |
| 4   | Reference to the name of the deployment resource.                                                                                                                                                                                                    |

Use the ``oc apply -f _`hello-hpa`_.yaml`` command to create the resource from the file.

The preceding example creates a horizontal pod autoscaler resource that scales based on CPU usage. Alternatively, it can scale based on memory usage by setting the resource name to `memory`, as in the following example:

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: hello
spec:
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - resource:
      name: `memory`
      target:
        averageUtilization: 80
_...output omitted..._
```

To create a horizontal pod autoscaler resource from the web console, click the Workloads → HorizontalPodAutoscalers menu. Click Create HorizontalPodAutoscaler and customize the YAML manifest.

---
**Note**

If an application uses more overall memory as the number of replicas increases, then it cannot be used with memory-based autoscaling.

---

